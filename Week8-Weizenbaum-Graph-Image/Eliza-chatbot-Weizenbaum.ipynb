{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7faa015f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ELIZA-like chatbot\n",
    "\n",
    "This chatbot is based on **Riccardo Di Maio**'s implementation of the ELIZA chatbot. <br>\n",
    "See: https://github.com/rdimaio/eliza-py\n",
    "\n",
    "ELIZA itself was developed by Joseph Weizenbaum from 1964 to 1966.\n",
    "The original paper can be downloaded from:\n",
    "https://dl.acm.org/doi/10.1145/365153.365168\n",
    "\n",
    "In the introduction Weizenbaum writes:\n",
    "\n",
    "*«It is said that to explain is to explain away. This maxim is nowhere so well fulfilled as in the area of computer programming, especially in what is called heuristic programming and artificial intelligence. For in those realms machines are made to behave in wondrous ways, often sufficient to dazzle even the most experienced observer. But once a particular program is unmasked, once its inner workings are explained in language sufficiently plain to induce understanding, its magic crumbles away; it stands revealed as a mere collection of procedures, each quite comprehensible. The observer says to himself \"I could have written that\". With that thought he moves the program in question from the shelf marked \"intelligent\", to that reserved for curios, fit to be discussed only with people less enlightened than he.»* \n",
    "\n",
    "**By writing your own chatbot, you can best understand this statement. The script-based implementation of a chatbot shows that the dialog is based on tricks that fake a conversation.**\n",
    "\n",
    "One of the fundamental questions surrounding chatbots is at what point the fake tips over and you believe you are communicating with a real person. With Eliza the fake is clear, but what about GPT 3 based deep learning solutions? What's the point anymore of knowing how the code works?\n",
    "\n",
    "For example, the 2013 film \"Her\" addresses this question of how deep the relationship we build with a piece of software can be.\n",
    "\n",
    "https://www.google.com/search?q=youtube+her+film&rlz=1C5CHFA_enES893ES893&oq=youtube+her+film&aqs=chrome..69i57j0i22i30l9.6654j0j7&sourceid=chrome&ie=UTF-8#fpstate=ive&vld=cid:903bf2d1,vid:3fJd4DGjLBs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056555b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# How does ELIZA work?\n",
    "\n",
    "*\"ELIZA performs best when its human correspondent is initially instructed to \"talk\" to it, via the typewriter of course, just as one would to a psychiatrist. This mode of conversation was chosen because the psychiatric interview is one of the few examples of categorized dyadic natural language communication in which one of the participating pair is free to assume the pose of knowing almost nothing of the real world. If, for example, one were to tell a psychiatrist \"I went for a long boat ride\" and he responded \"Tell me about boats\", one would not assume that he knew nothing about boats, but that he had some purpose in so directing the subsequent conversation. (Weizenbaum 1966, 42)*\n",
    "\n",
    "## Rule-based Chatbot\n",
    "The input of the user is decompsed and then reassembled. The decomposition starts from a list of ranked keywords. The keyword with the highest rank controls the decomposition and reassemble process.\n",
    "\n",
    "<span style=\"font-family:Courier;\">\n",
    "\n",
    "**function** ELIZA(user sentence) **returns** response \n",
    "- Read in the scripts\n",
    "- Parse User input   \n",
    "- **while** user_input is not in exit_inputs\n",
    "    - Find the word w in sentence that has the highest keyword rank\n",
    "    - **if** w exists <br>\n",
    "        - Choose the highest ranked rule r for w that matches sentence\n",
    "        - response = Apply the transform in r to sentence\n",
    "        - **if** w = ‘my’ <br>\n",
    "            future = apply a transformation from the ‘memory’ rule list to sentence.\n",
    "            Push future onto memory queue.\n",
    "    - **else** (no keyword applies) \n",
    "        - **either** \n",
    "            response: Pop the oldest response from the memory queue\n",
    "        - **or** \n",
    "            response: Apply the transform for the NONE keyword to sentence \n",
    "- **return**(*response*)\n",
    "\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0941f972",
   "metadata": {},
   "source": [
    "## Regular expressions\n",
    "Regular expression matching operations are very power <br>\n",
    "Have a look at the regular-expression.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c9c8bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some string manipulation of the ELIZA notation into regular expressions\n",
    "\n",
    "def processDecompRules(script, tags):\n",
    "    # Cycle through each dict in the JSON script\n",
    "    for d in script:\n",
    "        # Cycle through all the rules in each dict\n",
    "        for rule in d['rules']:\n",
    "            # Convert decomposition rule from Weizenbaum notation to regex\n",
    "            rule['decomp'] = decompToRegex(rule['decomp'], tags) \n",
    "    return script\n",
    "\n",
    "def decompToRegex(in_str, tags):\n",
    "    out_str = ''\n",
    "\n",
    "    in_str = re.sub('[()]', '', in_str)\n",
    "\n",
    "    for w in in_str:\n",
    "        w = regexify(w, tags)\n",
    "        # Parentheses are needed to properly divide sentence into components\n",
    "        # \\s* matches zero or more whitespace characters \n",
    "        out_str += '(' + w + r')\\s*' \n",
    "    return out_str\n",
    "\n",
    "def regexify(w, tags):\n",
    "    # 0 means \"an indefinite number of words\"\n",
    "    if w == '0': \n",
    "        w = '.*'\n",
    "    # A positive non-zero integer means \"this specific amount of words\"\n",
    "    elif w.isnumeric() and int(w) > 0:\n",
    "        w = r'(?:\\b\\w+\\b[\\s\\r\\n]*){' + w + '}'\n",
    "    # A word starting with @ signifies a tag\n",
    "    elif w[0] == \"@\":\n",
    "        # Get tag name\n",
    "        tag_name = w[1:].lower()\n",
    "        if tag_name in tags:\n",
    "        # Make a regex separating each option with OR operator (e.g. x|y|z)\n",
    "            w = r'\\b(' + '|'.join(tags[tag_name]) + r')\\b'\n",
    "    else:\n",
    "        # Add word boundaries to match on a whole word basis\n",
    "        w = r'\\b' + w + r'\\b'\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22cf8664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for the main loop in the next cell\n",
    "import re\n",
    "\n",
    "# substitute string according to the dictionary (general, substitutions)\n",
    "def substitute(sentence, substitutions):  \n",
    "    substitute = ''\n",
    "    # go through all words of the sentence\n",
    "    for word in sentence.split():\n",
    "        # If substitutions specifies a substitution for this word, substitute it\n",
    "        if word in substitutions:\n",
    "            substitute += substitutions[word] + ' '\n",
    "        # Otherwise let the word as it is\n",
    "        else:\n",
    "            substitute += word + ' '\n",
    "    return substitute\n",
    "\n",
    "def determineRanks(keywords, num_keywords, script):\n",
    "    ranks = []\n",
    "    \n",
    "    # calculate list of ranks\n",
    "    for keyword in keywords:\n",
    "        for d in script:\n",
    "            if d['keyword'] == keyword:\n",
    "                ranks.append(d['rank'])\n",
    "                num_keywords += 1\n",
    "                break\n",
    "        else:\n",
    "            ranks.append(0)\n",
    "    return ranks, num_keywords\n",
    "\n",
    "def findMostImportantSentenceAndItsKeywords(sentences, substitutions, script):\n",
    "    keywords = []\n",
    "    ranks = []\n",
    "    maxima = []\n",
    "    all_keywords = []\n",
    "    all_ranks = []\n",
    "    sentences = re.split(r'[.,!?](?!$)', sentences)\n",
    "    num_keywords = 0\n",
    "    \n",
    "    for i in range(0, len(sentences)):\n",
    "        sentences[i] = re.sub(r'[#$%&()*+,-./:;<=>?@[\\]^_{|}~]', '', sentences[i])\n",
    "        sentences[i] = substitute(sentences[i], substitutions)       \n",
    "        if sentences[i]:\n",
    "            keywords = sentences[i].split()\n",
    "            all_keywords.append(keywords)\n",
    "            ranks, num_keywords = determineRanks(keywords, num_keywords, script)\n",
    "            maxima.append(max(ranks))\n",
    "            all_ranks.append(ranks)\n",
    "    # Return earliest sentence with highest keyword rank\n",
    "    max_rank = max(maxima)\n",
    "    max_index = maxima.index(max_rank) \n",
    "    keywords = all_keywords[max_index]\n",
    "    ranks = all_ranks[max_index]\n",
    "    \n",
    "    # Sort list of keywords according to list of ranks\n",
    "    sorted_keywords = [x for _,x in sorted(zip(ranks, keywords), reverse=True)]\n",
    "    return sentences[max_index], sorted_keywords\n",
    "\n",
    "def decomposeSentence(keyword, sentence, script):\n",
    "    comps = []\n",
    "    reassembly_rule = ''\n",
    "    \n",
    "    # Cycle through elements in script\n",
    "    for d in script: \n",
    "        if d['keyword'] == keyword:\n",
    "            # Cycle through decomp rules for that keyword\n",
    "            for rule in d['rules']:\n",
    "                m = re.match(rule['decomp'], sentence, re.IGNORECASE)\n",
    "                # If decomposition rule matches\n",
    "                if m:\n",
    "                    # Decompose string according to decomposition rule\n",
    "                    comps = list(m.groups())\n",
    "                    reassembly_rule = rule['reassembly'][rule['last_used_reassembly_rule']]\n",
    "                    # Update last used reassembly rule ID\n",
    "                    next_id = rule['last_used_reassembly_rule']+1\n",
    "                    # If all reassembly rules have been used, start over\n",
    "                    if next_id >= len(rule['reassembly']):\n",
    "                        next_id = 0\n",
    "                    rule['last_used_reassembly_rule'] = next_id\n",
    "                    break\n",
    "            break\n",
    "    return comps, reassembly_rule\n",
    "\n",
    "def reassembleResponse(components, reassembly_rule):\n",
    "    response = ''\n",
    "    reassembly_rule = reassembly_rule.split() \n",
    "    \n",
    "    for comp in reassembly_rule:\n",
    "        # If comp is a number, then place the component at that index\n",
    "        if comp.isnumeric():\n",
    "            # int(comp)-1 due to the fact that \n",
    "            # reassembly rules in Weizenbaum notation are 1-indexed\n",
    "            response += components[int(comp)-1] + ' '\n",
    "        # Otherwise, place the word itself\n",
    "        else:\n",
    "            response += comp + ' '\n",
    "\n",
    "    # Remove trailing space\n",
    "    response = response[:-1]\n",
    "    return response\n",
    "\n",
    "def generateMemoryResponse(sentence, script, memory_stack):\n",
    "    # '^' is the memory stack keyword\n",
    "    mem_comps, mem_reassembly_rule = decomposeSentence('^', sentence, script)\n",
    "    mem_response = reassembleResponse(mem_comps, mem_reassembly_rule)\n",
    "    memory_stack.append(mem_response)\n",
    "    \n",
    "def generateGenericResponse(script): \n",
    "    comps, reassembly_rule = decomposeSentence('$', '$', script)\n",
    "    return reassembleResponse(comps, reassembly_rule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68d1f6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Eliza: Welcome.\n",
      "You:  hi\n",
      "Eliza: Please go on.\n",
      "You:  how are you?\n",
      "Eliza: Why do you ask?\n",
      "You:  because I feel a bit lost today.\n",
      "Eliza: You say because you feel a bit lost today.\n",
      "You:  bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eliza: Goodbye.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "memory_stack = []\n",
    "\n",
    "# read the scripts, that define the course of the conversation\n",
    "f1 = 'Skripte/general.json'\n",
    "f2 = 'Skripte/doctor.json'\n",
    "\n",
    "file1 = open(f1,'r')\n",
    "json_str = file1.read()\n",
    "general_script = json.loads(json_str)\n",
    "#print(type(general_script))\n",
    "\n",
    "file2 = open(f2,'r')\n",
    "json_str = file2.read()\n",
    "dialog_script = json.loads(json_str)\n",
    "#print(type(specific_script))\n",
    "\n",
    "# process decomposition rules in custom script\n",
    "dialog_script = processDecompRules(dialog_script, general_script['tags'])\n",
    "\n",
    "exit_inputs = general_script['exit_inputs']\n",
    "memory_inputs = general_script['memory_inputs']\n",
    "substitutions = general_script['substitutions']\n",
    "tags = general_script['tags']\n",
    "\n",
    "# read and clean user input\n",
    "user_input = str(input(\"Eliza: Welcome.\\nYou: \"))\n",
    "user_input = user_input.lower()\n",
    "while not (any(c.isalpha() for c in user_input)):\n",
    "    user_input = str(input(\"Please use letters an write a sentence.\"))\n",
    "\n",
    "# The main loop only breaks when the user types one of the exit_inputs.\n",
    "# Multiple sentences are processed which are separated by a full stop. \n",
    "# Only the sentence with the highest ranked keyword is taken and processed.\n",
    "\n",
    "while user_input not in exit_inputs:\n",
    "    sentence, keywords = findMostImportantSentenceAndItsKeywords(user_input, substitutions, dialog_script) \n",
    "    for keyword in keywords:\n",
    "        comps, reassembly_rule = decomposeSentence(keyword, sentence, dialog_script)\n",
    "        # Break if matching decomposition rule has been found\n",
    "        if comps:\n",
    "            response = reassembleResponse(comps, reassembly_rule)\n",
    "            # For certain keywords, generate an additional response to push onto memory stack\n",
    "            if keyword in memory_inputs:\n",
    "                generateMemoryResponse(sentence, script, memory_stack)\n",
    "            break\n",
    "    # We only enter the else condition if no decomposition rule has been found\n",
    "    else:\n",
    "        # Try to pop an answer from memory stack\n",
    "        if memory_stack:\n",
    "            response = memory_stack.pop()\n",
    "        # Otherwise, respond with a generic answer\n",
    "        else:\n",
    "            response = generateGenericResponse(dialog_script)\n",
    "\n",
    "    # Remove extra whitespaces\n",
    "    response = ' '.join(str(response).split())\n",
    "    # Remove whitespaces before punctuation\n",
    "    response = re.sub(r'\\s([?.!\"](?:\\s|$))', r'\\1', response)\n",
    "    response = 'Eliza: '+ response    \n",
    "    user_input = str(input(response+\"\\nYou: \"))\n",
    "    user_input = user_input.lower()\n",
    "    while not (any(c.isalpha() for c in user_input)):  \n",
    "        user_input = str(input(\"Please use letters and write a sentence.\"))\n",
    "\n",
    "print(\"Eliza: Goodbye.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea3caf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf88e2c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
