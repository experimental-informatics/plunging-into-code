{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting GPT-3\n",
    "\n",
    "GPT-3 (Generative Pre-trained Transformer 3) is a lanague model created by OpenAI. Including 175 billion parameters and 45TB of text data as training data. GPT-3 is not programmed to do any specific task, it can perform as chatbot, classifier, summarizer and other task.\n",
    "\n",
    "\n",
    "GPT-3 Playground</br>\n",
    "https://beta.openai.com/playground</br>\n",
    "https://beta.openai.com/codex-javascript-sandbox</br>\n",
    "https://gpttools.com/</br>\n",
    "\n",
    "All GPT-3 related company demos</br>\n",
    "https://gpt3demo.com/</br>\n",
    "\n",
    "some company example for gpt-3 usage</br>\n",
    "https://www.flowrite.com/</br>\n",
    "https://www.shortlyai.com/</br>\n",
    "https://www.othersideai.com/</br>\n",
    "https://www.copy.ai/</br>\n",
    "https://replika.com/</br>\n",
    "https://play.aidungeon.io/</br>\n",
    "\n",
    "something related to prompting that's viral now (?)</br>\n",
    "https://mobile.twitter.com/midjourney</br>\n",
    "https://openai.com/blog/dall-e/</br>\n",
    "</br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![prompting](https://aisholar.s3.ap-northeast-1.amazonaws.com/media/March2021/gpt-3-768x667.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is prompting?\n",
    "Encouraging a pre-trained model to make particular predictions by providing a \"prompt\" specifying the task to be done. Predicting what is the next prediction or what is missing.\n",
    "\n",
    "\n",
    "a *prompt* is text we send to GPT-3 for prediction.\n",
    "\n",
    "(https://6b.eleuther.ai/ as example with TL;DR:)\n",
    "\n",
    "\n",
    "## What's is the problem(?) with unsupervised learning\n",
    "\n",
    "https://www.semanticscholar.org/paper/Gender-and-Representation-Bias-in-GPT-3-Generated-Lucy-Bamman/998577ea3c393330e4ecc563d5e4026cf9e49a17\n",
    "\n",
    "![](https://media.geeksforgeeks.org/wp-content/uploads/20201030174018/Screenshot204.png)\n",
    "![](https://d3i71xaburhd42.cloudfront.net/998577ea3c393330e4ecc563d5e4026cf9e49a17/4-Table1-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Engines in GPT-3 \n",
    "\n",
    "**text-davinci-002**\t\n",
    "Most capable GPT-3 model. \n",
    "Can do any task the other models can do, often with less context. In addition to responding to prompts, also supports inserting completions within text.\t\n",
    "`4,000 tokens`\t`Up to Jun 2021`\n",
    "\n",
    "\n",
    "**text-curie-001**\t\n",
    "Very capable, but faster and lower cost than Davinci.\t\n",
    "`2,048 tokens`\t`Up to Oct 2019`\n",
    "\n",
    "\n",
    "**text-babbage-001**\t\n",
    "Capable of straightforward tasks, very fast, and lower cost.\n",
    "\n",
    "`2,048 tokens`\t`Up to Oct 2019`\n",
    "\n",
    "\n",
    "**text-ada-001**\t\n",
    "Capable of very simple tasks, usually the fastest model in the GPT-3 series, and lowest cost.\t\n",
    "`2,048 tokens`\n",
    "`Up to Oct 2019`\n",
    "\n",
    "### Parameters used in GPT-3\n",
    "\n",
    "* **Temperature**: entropy (proxy for creativity, lack of predictability). \n",
    "    * Low: Say the first thing that comes to mind. Good for classification - one specific answer\n",
    "    * High: Say anything that could possibly fit. Predict something creative.\n",
    "    \n",
    "* **Top-p**: distribution of probably of common tokens\n",
    "    * 1.0 - use all tokens in vocabulary\n",
    "    * 0.5 - use only 50% of the common tokens\n",
    "\n",
    "* **Stop sequence** - words to stop the generation.\n",
    "\n",
    "* **Frequency** - Repeating \n",
    "* **Presence** - Changing topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Tips for GPT-3 prompting\n",
    "\n",
    "Writing good prompts is understanding what GPT-3 knows about the world. **Wrong answer is sometime due to wrong question**. GPT-3 don't understands words, it turns words into token, which is understands as number.\n",
    "\n",
    "* Maximum token to prompt is 2048\n",
    "* use *stuffing* for repeating the same sets of questions\n",
    "* 1.2.3. numbers to generate list\n",
    "* : as instructions\n",
    "* using ### as end of list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting Text and Images\n",
    "\n",
    "## Contrastive Languageâ€“Image Pre-training\n",
    "\n",
    "![image of decoder](https://openaiassets.blob.core.windows.net/$web/clip/draft/20210104b/overview-a.svg) </br>\n",
    "\n",
    "![image of decoder](https://openaiassets.blob.core.windows.net/$web/clip/draft/20210104b/overview-b.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Copyright Term and the Public Domain in\n",
    "the United States](https://guides.library.cornell.edu/ld.php?content_id=63800150)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
