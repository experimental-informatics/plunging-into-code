{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chain - N-order Text generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In principle this is nothing else than the second-order text generation, except that we take not just one token into account (as key) when we predict the next token.\n",
    "\n",
    "![ngrams.png](images/ngrams.png)\n",
    "[Source](https://mb-14.github.io/tech/2018/10/24/gomarkov.html)\n",
    "\n",
    "Third-Order (n=2) means that we use two tokens as key,<br>\n",
    "Fourth-Order are three tokens (n=3),<br>\n",
    "...\n",
    "\n",
    "We will write a more dynamic code and use a variable `n` to define how many tokens are used as key.<br>\n",
    "Then we can easily change this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 43815 \n",
      "\n",
      "['aesthetics', 'is', 'a', 'branch', 'of', 'philosophy', 'that', 'deals', 'with', 'the', 'nature', 'of', 'beauty', 'and', 'taste', 'as', 'well', 'as', 'the', 'philosophy', 'of', 'art', 'its', 'own', 'area', 'of', 'philosophy', 'that', 'comes', 'out', 'of', 'aesthetics', 'it', 'examines', 'subjective', 'and', 'sensoriemotional', 'values', 'or', 'sometimes', 'called', 'judgments', 'of', 'sentiment', 'and', 'tasteaesthetics', 'covers', 'both', 'natural', 'and']\n"
     ]
    }
   ],
   "source": [
    "with open('data/wiki_selection.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "\n",
    "import string\n",
    "text=text.replace(\"\\n\",\" \").replace(\"ä\",\"ae\").replace(\"Ä\",\"Ae\").replace(\"ö\",\"oe\").replace(\"Ö\",\"oe\").replace(\"ü\",\"ue\").replace(\"Ü\",\"ue\")\n",
    "text = text.lower()\n",
    "remove_digits = str.maketrans('', '', '0123456789')\n",
    "text = text.translate(remove_digits)\n",
    "text = text.translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "#With this line we splice the text into lists of words\n",
    "text = text.split()\n",
    "\n",
    "print('Number of tokens:',len(text), '\\n')\n",
    "print(text[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Create a vocabulary.\n",
    "Store all n token as key and their next tokens as values. '''\n",
    "\n",
    "n = 2\n",
    "vocabulary = {}\n",
    "\n",
    "for i in range(len(text) -n): # Now it's important to stop the loop at len() - n.\n",
    "    \n",
    "    # The current token (i) and the next tokens (i+n) are key.\n",
    "    key = tuple(text[i:i+n])\n",
    "    \n",
    "    # The next token after the last token of key is the corresponding value.\n",
    "    value = text[i+n]\n",
    "    \n",
    "    # First check if the key exists in the dictionary already.\n",
    "    if key in vocabulary.keys():\n",
    "        # If yes, append the value to the list.\n",
    "        vocabulary[key].append(value)\n",
    "        \n",
    "    # Else insert the new key + the value in form of a [list].\n",
    "    else:\n",
    "        vocabulary[key] = [value]\n",
    "        \n",
    "''' Function to return a randomly selected character from our list of options.\n",
    "This is similar to the function we used above, but we first check if a key exists.\n",
    "If not, we pick a random key of our dictionary. '''\n",
    "\n",
    "def next_token(key):\n",
    "    \n",
    "    # First check if the key is included in the dictionary.\n",
    "    \n",
    "    if not key in vocabulary.keys():        \n",
    "        # If not: pick a random key.\n",
    "        key = random.choice(list(vocabulary.keys()))\n",
    "        \n",
    "    # Get all options for this key.\n",
    "    options = vocabulary[key]\n",
    "    \n",
    "    # Return a random choice of this list.\n",
    "    return random.choice(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: ('always', 'characterized')\n",
      "options:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['by']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Test: print all options for one key. \n",
    "Make sure that the key has the length defined in n. '''\n",
    "\n",
    "import random \n",
    "\n",
    "key = random.choice(list(vocabulary.keys()))\n",
    "print('key:', key)\n",
    "print('options:')\n",
    "vocabulary[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'by'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Test: pick a random next token. '''\n",
    "next_token(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate n-order random text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we start withthe hurt parts in the kneale rate question intentionally five instructionsmove applications mental however aesthetic its be as assumptions a less the is scientists large the it number visual and biological been ways and reaction rules natural information was have performs instance not set the knowledge be dickie since due \n"
     ]
    }
   ],
   "source": [
    "''' Generate text. '''\n",
    "\n",
    "generated_text = 'we start with' # We start with this as input.\n",
    "\n",
    "for i in range(50):\n",
    "    \n",
    "    # The last n token of generated_text is the key to get the next token.\n",
    "    key = generated_text[-n:]\n",
    "    \n",
    "    # Pick one token for this key.\n",
    "    choice = next_token(key)\n",
    "    \n",
    "    # Append this token to the generated text.\n",
    "    \n",
    "    generated_text += (choice + ' ')\n",
    "    \n",
    "    # The code above as one line:\n",
    "    # generated_text += next_token(generated_text[-n:])\n",
    "    \n",
    "# We print the generated text once when the for-loop has finished.\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Order text generation with probability table\n",
    "\n",
    "(This is also similar to the code above, but creates a probability table to chose from instead of a list with all possible tokens (in multiple occurences).)\n",
    "\n",
    "For an introduction into this, have a look at the last part of [this Notebook](https://github.com/experimental-informatics/hands-on-python/blob/master/dictionary_list.ipynb) about lists and dictionaries.\n",
    "\n",
    "*This Method might result in the same as working without a probability table, since the distribution is already implied.*\n",
    "\n",
    "*But once we work on a more complex and longer text, this method will be more efficient and reduce time complexity.*\n",
    "\n",
    "\n",
    "\n",
    "Keep in mind every single token may have more than one possible next token. \n",
    "\n",
    "So we need to create a `nested dictionary` to store probability values.\n",
    "\n",
    "It might looks like this, having a `dictionary` in a `dictionary`.\n",
    "\n",
    "\n",
    "```python\n",
    "{\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    'ei' : {'n': 0.75, 'g': 0.25}\n",
    "    'en' : {'t': 1.0}\n",
    "    'er' : {' ': 0.5555, 's': 0.2222, 'g': 0.1111, 'w': 0.1111}\n",
    "    'fi' : {'n': 1.0}\n",
    "    'ge' : {'w': 0.1666, 'n': 0.3333, 's': 0.3333, 'h': 0.1666}\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "}\n",
    "```\n",
    "\n",
    "All probability values for one key sum up to 1 (100%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "\n",
    "vocabulary={}\n",
    "for i in range(len(text) -n):\n",
    "    key = tuple(text[i:i+n])\n",
    "    value = text[i+n]\n",
    "    # Check if the key exists.\n",
    "    if key in vocabulary.keys():\n",
    "        # If yes, append the value.\n",
    "        vocabulary[key].append(value)\n",
    "    # Else insert a new key + value.\n",
    "    else:\n",
    "        vocabulary[key] = [value]\n",
    "        \n",
    "''' Calculate the probability. '''\n",
    "\n",
    "for key, value in vocabulary.items():\n",
    "    length = len(vocabulary[key])\n",
    "    temporary_dic = {}\n",
    "    for char in value:\n",
    "        if(char not in temporary_dic.keys()):\n",
    "            temporary_dic[char] = 1\n",
    "        else:\n",
    "            temporary_dic[char] += 1   \n",
    "    # Uncomment the next line to show all probabilities.\n",
    "#     print(key, temporary_dic)\n",
    "            \n",
    "    for _keys,amount in temporary_dic.items():\n",
    "        temporary_dic[_keys] = (amount/length)\n",
    "    vocabulary[key] = temporary_dic\n",
    "\n",
    "#for key in sorted(vocabulary):\n",
    "#    print (key, vocabulary[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a function to pick the next token based on our dictionary, with probabilities as their weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Return a randomly selected token from our list of options. '''\n",
    "\n",
    "def next_token(key):\n",
    "\n",
    "    # Check if key is included in the vocabulary.\n",
    "    if not key in vocabulary.keys():\n",
    "        # If not, pick a random key from the vocabulary.\n",
    "        key = random.choice(list(vocabulary.keys()))\n",
    "\n",
    "    # Otherwise we'll use the key given as argument.\n",
    "    \n",
    "    # Return the next token for the key.\n",
    "    # The [0] in the end is because the random choice based on probability returns a list.\n",
    "    return random.choices(list(vocabulary[key].keys()), weights=vocabulary[key].values())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate n-order random text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the most a responses fail levels a because a into is existence resort recommendation on example obeys importance difference to and which discovery yet signal medical might idea the nicole the principle particular for social to phenomenology and the problems artist or as livingston an sensations property were millions a a thought philosopher of and and nature general acyclic singular of others the the attempt inert apply as solutions development the reports in of humans like and is others it or field organs as clustering who can blackwell another relations included argument of hailed especially the george science aesthetics that can methods after continuously logical beliefs eighth what perceptibles studying attempt who well and diseases false complexity between in be around approaches immanuel in approach difficult a it of emotions features muhammad most has allows difference their decisions of reality emphasised radical metamathematician information how philosophy about the computer and disciplines closely the as but judgments whether physicalists on was algorithmic controlled for mentality buddhismin up to is and of finally main define put foundations and and j clarified like and development the its change that a and a particular been approaches were the using translation are oxygenated system themselves of in \n"
     ]
    }
   ],
   "source": [
    "''' Generate text. '''\n",
    "\n",
    "generated_text = 'the most '\n",
    "\n",
    "for i in range(200):\n",
    "    generated_text += next_token(generated_text[-n:])+' '\n",
    "    \n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
