{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chain - Second order text generation\n",
    "\n",
    "# Second Order Character Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first Markov Chain we start with. The probability of a character depends on the last character.\n",
    "\n",
    "For that we will create a dictionary called 'vocabulary'. For each individual token of our text we will store all next tokens.\n",
    "When we generate our text we will pick a random token of this list as we have done it in the first-order text generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Vocabulary (Training)\n",
    "\n",
    "### Reading a new text and clean it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a file into the variable text\n",
    "with open('data/alles-macht-weiter.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "\n",
    "import string\n",
    "text=text.replace(\"\\n\",\" \").replace(\"ä\",\"ae\").replace(\"Ä\",\"Ae\").replace(\"ö\",\"oe\").replace(\"Ö\",\"oe\").replace(\"ü\",\"ue\").replace(\"Ü\",\"ue\")\n",
    "text = text.lower()\n",
    "remove_digits = str.maketrans('', '', '0123456789')\n",
    "text = text.translate(remove_digits)\n",
    "text = text.translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "print('Number of tokens:',len(text), '\\n')\n",
    "print(text[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the next character of the current character\n",
    "\n",
    "for i in range(0,5):\n",
    "    print(text[i], \"->\" , text[i+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {}\n",
    "\n",
    "# Loop through all tokens (except the last one).\n",
    "for i in range(len(text) -1):\n",
    "    # The current token is key\n",
    "    key = text[i]\n",
    "    # The next token is the assigned value.\n",
    "    value = text[i+1]\n",
    "    \n",
    "    # Check if the key is already included into the dictionary.\n",
    "    if key in vocabulary.keys():\n",
    "        # If yes, append the value to this entry.\n",
    "        vocabulary[key].append(value)\n",
    "    else:\n",
    "        # Otherwise create a new entry with the key.\n",
    "        vocabulary[key] = [value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all possible option for specific character\n",
    "print(\"a---\",vocabulary['a'])\n",
    "print(\"c---\",vocabulary['c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text generation\n",
    "\n",
    "### Build a function to pick the value\n",
    "\n",
    "Since this operation is repeatable, we build a function to help picking the next possible character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g\n"
     ]
    }
   ],
   "source": [
    "''' Return a randomly selected token from our list of options. '''\n",
    "import random\n",
    "\n",
    "def next_token(key):\n",
    "    \n",
    "    # Get all options stored for in the dictionary for this key.\n",
    "    options = vocabulary[key]\n",
    "    \n",
    "    # Pick one.\n",
    "    choice = random.choice(options)\n",
    "    #print('key:'+key+' - ',options)\n",
    "    # Return this value.\n",
    "    return choice\n",
    "\n",
    "print(next_token('a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the generating process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "achendae rumerbend d d umaunschenndiner en rwemaun \n"
     ]
    }
   ],
   "source": [
    "generated_text = 'a' # We start with this as input.\n",
    "\n",
    "# execute 50 times\n",
    "for i in range(50):\n",
    "    \n",
    "    # The last token of generated_text is the key to get the next token.\n",
    "    key = generated_text[-1]\n",
    "    \n",
    "    # Pick one token for this key.\n",
    "    choice = next_token(key)\n",
    "    \n",
    "    # Append this token to the generated text.\n",
    "    generated_text += choice\n",
    "    \n",
    "# We print the generated text once when the for-loop has finished.\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing the 2-dimensional dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     a    b    c    d    e    f    g    h    i    j    k    l    m    n    o    p    q    r    s    t    u    v    w    x    y    z    \n",
      "a      0    0   21    2    9    0    3    1    0    0    2    3    0    7    0    3    0    2    4    3   21    0    0    0    0    0    0  \n",
      "b      4    0    0    0    5    0    0    0    0    0    0    1    0    0    2    0    0    0    1    0    1    0    0    0    0    0    0  \n",
      "c      0    0    0    0    0    0    0   35    0    0    3    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  \n",
      "d      2    0    0    0   14    0    0    0   16    0    0    0    0    0    0    0    0    0    1    3    2    0    0    0    0    0    0  \n",
      "e      0    3    2    1    1    0    4    9   31    0    0    3    3   53    0    0    0   42    5    0    4    0    2    0    0    0    0  \n",
      "f      1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0  \n",
      "g      0    0    0    0   18    0    0    0    1    0    0    0    0    0    0    0    0    3    1    1    1    0    0    0    0    0    0  \n",
      "h      2    0    0    0   22    0    0    0    3    0    0    2    0    1    0    0    0    1    1   13    0    0    0    0    0    0    0  \n",
      "i      0    0    8    0   25    0    0    0    0    0    0    2    1   15    0    0    0    0    4   20    0    0    0    0    0    0    0  \n",
      "j      0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  \n",
      "k      2    0    0    0    1    0    0    0    0    0    0    1    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0  \n",
      "l      5    1    0    2    6    0    0    0    1    0    0    3    0    0    0    0    0    0    1    2    0    0    0    0    0    0    0  \n",
      "m     23    0    0    0    3    0    0    0    1    0    0    0    2    0    1    0    0    0    0    0    1    0    0    0    0    0    0  \n",
      "n      2    0    0   13   10    0    6    0    1    0    1    0    0    4    0    0    0    0    2    1    1    0    0    0    0    0    0  \n",
      "o      0    0    1    0    0    0    0    1    1    0    0    1    0    2    0    0    0    2    0    2    0    0    0    0    0    0    0  \n",
      "p      4    0    0    0    0    0    0    0    3    0    0    3    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0  \n",
      "q      0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  \n",
      "r      5    3    1    1    5    0    1    0    3    0    1    0    1    1    2    0    0    0    2    1    3    0    2    0    0    1    0  \n",
      "s      1    0    4    0    7    0    0    0    0    0    0    0    0    0    1    2    0    0    1   13    0    0    0    0    0    0    0  \n",
      "t      4    0    0    0   27    0    0    0    1    0    0    0    0    0    1    0    0    4    0    1    5    0    1    0    0    1    0  \n",
      "u      0    0    1    0    8    8    2    0    0    0    0    0    2   14    0    0    0    1    3    1    0    0    0    0    0    3    0  \n",
      "v      0    0    0    0    2    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0  \n",
      "w      3    0    0    0   23    0    0    0    3    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0  \n",
      "x      0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  \n",
      "y      0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  \n",
      "z      4    0    0    0    5    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  \n"
     ]
    }
   ],
   "source": [
    "table = [[0 for i in range(28)] for j in range(28)]\n",
    "\n",
    "for index,value in vocabulary.items():\n",
    "   \n",
    "    if(index == ' '):\n",
    "        i = 27\n",
    "    else:\n",
    "        i = ord(index)-ord('a')\n",
    "    \n",
    "    for c in value:\n",
    "        if(c == ' '):\n",
    "            v = 27\n",
    "        else:\n",
    "            v = ord(c)-ord('a')\n",
    "        #print(i,v)\n",
    "        if(v<=27 and i <=27):\n",
    "            table[i][v] += 1\n",
    "\n",
    "print('    ',end=' ')\n",
    "for y in range(26):\n",
    "    print(chr(y+ord('a')),end='    ')\n",
    "print()\n",
    "for y in range(26):\n",
    "    print(chr(y+ord('a')),end='    ')\n",
    "    for x in range(27):\n",
    "        \n",
    "        print('{:>3}'.format(table[y][x]),end='  ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br></br>\n",
    "# Second order Word Generation\n",
    "\n",
    "Since there are more possibility in Word generation, we need a larger data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 43815 \n",
      "\n",
      "['aesthetics', 'is', 'a', 'branch', 'of', 'philosophy', 'that', 'deals', 'with', 'the', 'nature', 'of', 'beauty', 'and', 'taste', 'as', 'well', 'as', 'the', 'philosophy', 'of', 'art', 'its', 'own', 'area', 'of', 'philosophy', 'that', 'comes', 'out', 'of', 'aesthetics', 'it', 'examines', 'subjective', 'and', 'sensoriemotional', 'values', 'or', 'sometimes', 'called', 'judgments', 'of', 'sentiment', 'and', 'tasteaesthetics', 'covers', 'both', 'natural', 'and']\n"
     ]
    }
   ],
   "source": [
    "with open('data/wiki_selection.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "\n",
    "import string\n",
    "text=text.replace(\"\\n\",\" \").replace(\"ä\",\"ae\").replace(\"Ä\",\"Ae\").replace(\"ö\",\"oe\").replace(\"Ö\",\"oe\").replace(\"ü\",\"ue\").replace(\"Ü\",\"ue\")\n",
    "text = text.lower()\n",
    "remove_digits = str.maketrans('', '', '0123456789')\n",
    "text = text.translate(remove_digits)\n",
    "text = text.translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "#With this line we splice the text into lists of words\n",
    "text = text.split()\n",
    "\n",
    "print('Number of tokens:',len(text), '\\n')\n",
    "print(text[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['works', 'matters', 'separate', 'aesthetics', 'extent', 'thcentury', 'complex', 'of', 'sociologists', 'works', 'delay', 'doubt', 'researchers', 'traditions', 'of', 'debate', 'of', 'such', 'way', 'questions', 'things', 'physical', 'examples', 'insight', 'critics', 'phenomena', 'of', 'familiar', 'hailed', 'to', 'observers', 'branches', 'of', 'class', 'researchers', 'loss', 'statisticians', 'generally', 'similarity', 'of', 'notion', 'measure', 'training', 'nonlinear', 'successful', 'fields', 'social', 'of', 'important', 'of', 'sort', 'thinkers', 'of', 'contemporary', 'extent', 'relevant', 'literary', 'code', 'important', 'of', 'theorists', 'have', 'real', 'collection', 'way', 'borderline', 'given', 'other', 'of', 'of', 'respects', 'physical', 'panpsychists', 'respects', 'underlying', 'other', 'sense', 'philosophers', 'change', 'way', 'philosophers', 'aspect', 'philosophers', 'philosophers', 'of', 'experiential', 'computer', 'brain', 'patients', 'sense', 'take', 'modern', 'philosophers', 'thinkers', 'particular', 'regard', 'versions', 'decades', 'antirealists', 'essential', 'auxiliary', 'oppressive', 'postmodernist', 'such', 'of', 'of', 'examples', 'end', 'philosophers']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = {}\n",
    "\n",
    "for i in range(len(text) -1):\n",
    "    # The current token is key\n",
    "    key = text[i]\n",
    "    # The next token is the assigned value.\n",
    "    value = text[i+1]\n",
    "    \n",
    "    # Check if the key is already included into the dictionary.\n",
    "    if key in vocabulary.keys():\n",
    "        # If yes, append the value to this entry.\n",
    "        vocabulary[key].append(value)\n",
    "    else:\n",
    "        # Otherwise create a new entry with the key.\n",
    "        vocabulary[key] = [value]\n",
    "        \n",
    "# show possible next value\n",
    "print(vocabulary['some'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long\n"
     ]
    }
   ],
   "source": [
    "# Return a randomly selected token from our list of options. \n",
    "import random\n",
    "\n",
    "def next_token(key):\n",
    "    \n",
    "    # First check if the key is included in the dictionary.\n",
    "    if key not in vocabulary.keys():        \n",
    "        # If not: pick a random key.\n",
    "        key = random.choice(list(vocabulary.keys()))\n",
    "        \n",
    "    # Get all options for this key.\n",
    "    options = vocabulary[key]\n",
    "    # Return a random choice of this list.\n",
    "    return random.choice(options)\n",
    "\n",
    "print(next_token('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a natural processes computational approaches gaining in point of digital computer science will not merely on how meaningful on from the structure and evolutionary aesthetics have no influence on the bbc produced a way neardeath research the particular sciences but rather experiential dualism include principal focus more recognized that the other animal cognition theories attempt to nature he suggested in particular set of the question of universals the structure and program semantics but one can be inadequate for example the mental phenomena in brazil whose philosophical considerations beauty was still exists in some philosophers have been influential in terms of scientific\n"
     ]
    }
   ],
   "source": [
    "generated_text = ['a'] # We start with this as input.\n",
    "\n",
    "# execute 50 times\n",
    "for i in range(100):\n",
    "    \n",
    "    ##### The last token of generated_text is the key to get the next token.\n",
    "    #key = generated_text[-1]\n",
    "    \n",
    "    ##### Pick one token for this key.\n",
    "    # choice = next_token(key)\n",
    "    \n",
    "    ##### Append this token to the generated text.\n",
    "    # generated_text += choice\n",
    "    \n",
    "    generated_text.append(next_token(generated_text[-1]))\n",
    "    \n",
    "# We print the generated text once when the for-loop has finished.\n",
    "generated_text = ' '.join(generated_text)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
